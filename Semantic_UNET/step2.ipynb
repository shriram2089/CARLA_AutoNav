{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592e672-8896-4e0a-a91d-a50423bd1dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing cycle  0\n",
      "Commencing cycle  1\n",
      "Commencing cycle  2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is image generation script as sem_im_gen_no_traffic.py, the same weather loop\n",
    "but now in autopilot with other tarffic\n",
    "\n",
    "\n",
    "You must create folder structure for out put images BEFORE running\n",
    "In the folder where you launch jupyter notebook, these these\n",
    " out_sem/rgb    - this folder will contain RGB images\n",
    " out_sem/sem    - this will contain semantic images\n",
    "\n",
    "Change the load_world command to load a different town\n",
    "Watch for traffic jams - you may need to sop the process pressing Q multiple times\n",
    "(one for each remaining weather loop)\n",
    " \n",
    "if you get this error\n",
    "cv2.error: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\\n",
    "    core\\src\\matrix_operations.cpp:67: error: (-215:Assertion failed) src[i].dims <= 2 ...\n",
    "\n",
    "Just re-run the code again\n",
    "'''\n",
    "\n",
    "import carla #the sim library itself\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import time\n",
    "import random\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "client.load_world('Town03')\n",
    "\n",
    "world = client.get_world()\n",
    "traffic_manager = client.get_trafficmanager(8000)\n",
    "\n",
    "blueprints = world.get_blueprint_library().filter('*vehicle*')\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "# clean up\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.1\n",
    "settings.no_rendering_mode = True\n",
    "traffic_manager.set_synchronous_mode(True)\n",
    "traffic_manager.global_percentage_speed_difference(70)\n",
    "\n",
    "world.apply_settings(settings)\n",
    "    \n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], random.choice(spawn_points))\n",
    "\n",
    "# generate traffic limeted number\n",
    "counter = 0\n",
    "traffic = []\n",
    "random.shuffle(spawn_points)\n",
    "for n, transform in enumerate(spawn_points):\n",
    "    counter +=1\n",
    "    if counter > len(spawn_points)/3: # good volume of traffic - up to 1/3 of available spawn points\n",
    "        break\n",
    "    blueprint = random.choice(blueprints)\n",
    "    traffic_vehicle = world.try_spawn_actor(blueprint, transform)\n",
    "    if traffic_vehicle != None:# spawn the cars and set their autopilot and light state all together\n",
    "        traffic.append(traffic_vehicle)\n",
    "        traffic_vehicle.set_light_state(carla.VehicleLightState.LowBeam)\n",
    "        traffic_vehicle.set_autopilot(True)\n",
    "\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "    \n",
    "def rgb_callback(image,data_dict):\n",
    "    data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "if vehicle == None:\n",
    "    print(\"Re-start the sim\")\n",
    "else:\n",
    "    #lights always on\n",
    "    vehicle.set_light_state(carla.VehicleLightState.LowBeam)\n",
    "    vehicle.set_autopilot(True)\n",
    "    \n",
    "    #camera mount offset on the car - you can tweak these to each car to avoid any parts of the car being in the view\n",
    "    CAMERA_POS_Z = 1.3 \n",
    "    CAMERA_POS_X = 1.4 \n",
    "\n",
    "    #semantic camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "    #normal rgb camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_rgb = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "\n",
    "    image_w = 640\n",
    "    image_h = 480\n",
    "\n",
    "    camera_data = {'sem_image': np.zeros((image_h,image_w,4)),\n",
    "                   'rgb_image': np.zeros((image_h,image_w,4))}\n",
    "\n",
    "    # this actually opens a live stream from the cameras\n",
    "    camera_sem.listen(lambda image: sem_callback(image,camera_data))\n",
    "    camera_rgb.listen(lambda image: rgb_callback(image,camera_data))\n",
    "\n",
    "\n",
    "    # get all drivable locations on the map\n",
    "    all_roads = world.get_map().get_topology()\n",
    "    #loop 1 time of day dry\n",
    "    for i in range(10):\n",
    "        print('Commencing cycle ',i)\n",
    "        weather = carla.WeatherParameters(\n",
    "                cloudiness=random.randint(0,100),\n",
    "                precipitation=random.randint(0,100),\n",
    "                sun_altitude_angle=random.randint(0,100),\n",
    "                precipitation_deposits =random.randint(0,100),\n",
    "                fog_density =random.choice([0.0,0.1,0.3,0.4,0.95]),\n",
    "                wetness = random.randint(0,100))\n",
    "        world.set_weather(weather)\n",
    "        img_counter = 0\n",
    "        prev_position = vehicle.get_transform()\n",
    "        while img_counter < 200:\n",
    "            world.tick()\n",
    "            current_position = vehicle.get_transform()\n",
    "            rgb_im = camera_data['rgb_image']\n",
    "            sem_im = camera_data['sem_image']\n",
    "            im_h = cv2.hconcat([rgb_im,sem_im])\n",
    "            cv2.imshow('2 cameras', im_h)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            #write images\n",
    "            if current_position.location.distance(prev_position.location)>10:\n",
    "                prev_position = current_position\n",
    "                img_counter += 1\n",
    "                time_grab = time.time_ns()\n",
    "                cv2.imwrite('out_sem/rgb/%06d.png' % time_grab, rgb_im)\n",
    "                cv2.imwrite('out_sem/sem/%06d.png' % time_grab, sem_im)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    camera_sem.stop() # this is the opposite of camera.listen\n",
    "    camera_rgb.stop() \n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21477c-a9ab-4c1b-9edf-c7d9a5184cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CarlaSim",
   "language": "python",
   "name": "carla-sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
