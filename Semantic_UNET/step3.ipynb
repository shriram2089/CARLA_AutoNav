{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353aca2a-0e44-4320-87f6-938d0081a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing cycle  0\n",
      "Commencing cycle  1\n",
      "Commencing cycle  2\n",
      "Commencing cycle  3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22340\\1671814457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaypoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[0mrgb_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rgb_image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0msem_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sem_image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is a script to generate:\n",
    "1. Normal RGB images\n",
    "2. Semantic segmentation versions of RGB images (labels)\n",
    "\n",
    "Under different weather and lighting conditions\n",
    "\n",
    "Camera parameters are closest to real Tesla Model 3 front facing camera\n",
    "\n",
    "The end purpose of this is to train a vision model using output images\n",
    "so the model could be tested on real Tesla footage and would generate\n",
    "a mask to show drivable surfave in front of the car\n",
    "\n",
    "This version of code generate images with traffic\n",
    "\n",
    "It is recommended to re-start the simulator each time you run this\n",
    "\n",
    "You must create folder structure for output images BEFORE running\n",
    " In the folder where you launch jupyter notebook, these these\n",
    " out_sem/rgb    - this folder will contain RGB images\n",
    " out_sem/sem    - this will contain semantic images\n",
    "\n",
    " '''\n",
    "import carla #the sim library itself\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import time\n",
    "import random\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "client.load_world('Town03')\n",
    "\n",
    "world = client.get_world()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "# clean up\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.1\n",
    "settings.no_rendering_mode = True\n",
    "world.apply_settings(settings)\n",
    "    \n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], spawn_points[0])\n",
    "\n",
    "# callbacks for cameras\n",
    "def sem_callback(image,data_dict):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "    \n",
    "def rgb_callback(image,data_dict):\n",
    "    data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "if vehicle == None:\n",
    "    print(\"Re-start the sim and try again. No connection to the simulator.\")\n",
    "else:\n",
    "\n",
    "    #lights always on\n",
    "    vehicle.set_light_state(carla.VehicleLightState.LowBeam)\n",
    "\n",
    "    #camera mount offset on the car - you can tweak these to each car to avoid any parts of the car being in the view\n",
    "    CAMERA_POS_Z = 1.3 \n",
    "    CAMERA_POS_X = 1.4 \n",
    "\n",
    "    #semantic camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "    #normal rgb camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_rgb = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "\n",
    "    image_w = 640\n",
    "    image_h = 480\n",
    "\n",
    "    camera_data = {'sem_image': np.zeros((image_h,image_w,4)),\n",
    "                   'rgb_image': np.zeros((image_h,image_w,4))}\n",
    "\n",
    "    # this actually opens a live stream from the cameras\n",
    "    camera_sem.listen(lambda image: sem_callback(image,camera_data))\n",
    "    camera_rgb.listen(lambda image: rgb_callback(image,camera_data))\n",
    "\n",
    "\n",
    "    # get all drivable locations on the map\n",
    "    all_roads = world.get_map().get_topology()\n",
    "    #loop for random weather conditios\n",
    "    for i in range(10):\n",
    "        print('Commencing cycle ',i)\n",
    "        weather = carla.WeatherParameters(\n",
    "                cloudiness=random.randint(0,100),\n",
    "                precipitation=random.randint(0,100),\n",
    "                sun_altitude_angle=random.randint(0,100),\n",
    "                precipitation_deposits =random.randint(0,100),\n",
    "                fog_density =random.choice([0.0,0.1,0.3,0.4,0.95]),\n",
    "                wetness = random.randint(0,100))\n",
    "        world.set_weather(weather)\n",
    "        for waypoint in all_roads:\n",
    "            world.tick()\n",
    "            vehicle.set_transform(waypoint[0].transform)\n",
    "            time.sleep(0.5)\n",
    "            rgb_im = camera_data['rgb_image']\n",
    "            sem_im = camera_data['sem_image']\n",
    "            #show images\n",
    "            im_h = cv2.hconcat([rgb_im,sem_im])\n",
    "            cv2.imshow('2 cameras', im_h)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            #write images\n",
    "            time_grab = time.time_ns()\n",
    "            cv2.imwrite('out_sem/rgb/%06d.png' % time_grab, rgb_im)\n",
    "            cv2.imwrite('out_sem/sem/%06d.png' % time_grab, sem_im)\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    camera_sem.stop() # this is the opposite of camera.listen\n",
    "    camera_rgb.stop() \n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8096db-b778-444e-a827-f046b776ec98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CarlaSim",
   "language": "python",
   "name": "carla-sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
