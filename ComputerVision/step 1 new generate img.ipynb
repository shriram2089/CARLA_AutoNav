{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is extra images when a car will be rotated in a lane while shown a correct angle to straighten out\n",
    "\n",
    "\n",
    "\n",
    "# Modifying previous preps notebook code to generate\n",
    "# training images\n",
    "# Note: this generates some black only images - they need to be deleted before training the model\n",
    "# you can sort files by size - they will be all 3kb \n",
    "# Also you may need to run this with version 9.13 of Carla\n",
    "\n",
    "#all imports\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('E:/CARLA/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "SPEED_THRESHOLD = 2 #defines when we get close to desired speed so we drop the throttle\n",
    "\n",
    "# Max steering angle\n",
    "MAX_STEER_DEGREES = 40\n",
    "#Max spin angle\n",
    "MAX_SPIN = 20\n",
    "# This is max actual angle with Mini under steering input=1.0\n",
    "STEERING_CONVERSION = 75\n",
    "\n",
    "#camera mount offset on the car - this mimics Tesla Model 3 view \n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "# utility function for camera listening \n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "# utility function for camera listening \n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "# function to get angle between the car and target waypoint\n",
    "def get_angle(car,wp):\n",
    "    '''\n",
    "    this function returns degrees between the car's direction \n",
    "    and direction to a selected waypoint\n",
    "    '''\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    # vector to waypoint\n",
    "    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    \n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "def get_proper_angle(car,wp_idx,rte):\n",
    "    '''\n",
    "    This function uses simple fuction above to get angle but for current\n",
    "    waypoint and a few more next waypoints to ensure we have not skipped\n",
    "    next waypoint so we avoid the car trying to turn back\n",
    "    '''\n",
    "    # create a list of angles to next 5 waypoints starting with current\n",
    "    next_angle_list = []\n",
    "    for i in range(10):\n",
    "        if wp_idx + i*3 <len(rte)-1:\n",
    "            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))\n",
    "    idx = 0\n",
    "    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:\n",
    "        idx +=1\n",
    "    return wp_idx+idx*3,next_angle_list[idx]  \n",
    "\n",
    "def get_distant_angle(car,wp_idx,rte, delta):\n",
    "    '''\n",
    "    This function modifies the function above to get angle to a waypoint\n",
    "    at a distance so we could use it for training image generation\n",
    "    \n",
    "    We will display the angle for now in the 'telemetry' view so\n",
    "    we could play with how far forward we need to pick the waypoint\n",
    "    '''\n",
    "    if wp_idx + delta < len(rte)-1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte)-1\n",
    "    # check for intersection within the \"look forward\"\n",
    "    # so we do not give turn results when just following the road\n",
    "    intersection_detected = False\n",
    "    for x in range(i-wp_idx):\n",
    "        if rte[wp_idx+x][0].is_junction:\n",
    "             intersection_detected = True\n",
    "    angle = get_angle(car,rte[i][0])\n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    elif angle <-10:\n",
    "        result = -1\n",
    "    elif angle>10:\n",
    "        result =1\n",
    "    else:\n",
    "        result = 0    \n",
    "    return result\n",
    "\n",
    "def draw_route(wp, route,seconds=3.0):\n",
    "    #draw the next few points route in sim window - Note it does not\n",
    "    # get into the camera of the car\n",
    "    if len(route)-wp <25: # route within 25 points from end is red\n",
    "        draw_colour = carla.Color(r=255, g=0, b=0)\n",
    "    else:\n",
    "        draw_colour = carla.Color(r=0, g=0, b=255)\n",
    "    for i in range(10):\n",
    "        if wp+i<len(route)-2:\n",
    "            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n",
    "                color=draw_colour, life_time=seconds,\n",
    "                persistent_lines=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    '''\n",
    "    retruns a random route for the car/veh\n",
    "    out of the list of possible locations locs\n",
    "    where distance is longer than 100 waypoints\n",
    "    '''    \n",
    "    point_a = position.location #we start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # now let' pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: # we start trying all spawn points \n",
    "                                #but we just exclude first at zero index\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "\n",
    "# connect to the sim \n",
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "#client.load_world('Town03')\n",
    "\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.1\n",
    "settings.no_rendering_mode = False\n",
    "world.apply_settings(settings)\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "#clean up any existing cars\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "\n",
    "#look for a blueprint of Tesla m3 car\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "def exit_clean():\n",
    "    #clean up\n",
    "    cv2.destroyAllWindows()\n",
    "    camera_sem.stop()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    return None\n",
    "\n",
    "\n",
    "#main loop\n",
    "img_counter = 0\n",
    "quit = False\n",
    "while img_counter < 100:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    "    # setting semantic camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = 640\n",
    "    image_h = 480\n",
    "\n",
    "    camera_data = {'sem_image': np.zeros((image_h,image_w,4)),\n",
    "                   'rgb_image': np.zeros((image_h,image_w,4))}\n",
    "\n",
    "        # this actually opens a live stream from the cameras\n",
    "    camera_sem.listen(lambda image: sem_callback(image,camera_data))\n",
    "    # adding collision sensor\n",
    "\n",
    "    #setting RGB Camera \n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640') \n",
    "    camera_bp.set_attribute('image_size_y', '360')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "  \n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('RGB Camera',camera_data['rgb_image'])\n",
    "\n",
    "\n",
    "\n",
    "    prev_position = vehicle.get_transform()\n",
    "    # getting a random route for the car\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    curr_wp = 0\n",
    "    world.tick()\n",
    "    \n",
    "    while curr_wp<len(route)-6 and img_counter < 100:\n",
    "\n",
    "        # move the car to next waypoint\n",
    "        curr_wp +=1\n",
    "        vehicle.set_transform(route[curr_wp][0].transform)\n",
    "        time.sleep(2)\n",
    "        world.tick()\n",
    "                \n",
    "        # first position the car on the route and take normal shot (without spinning)\n",
    "        _, predicted_angle = get_proper_angle(vehicle,curr_wp+5,route)\n",
    "        steer_input = predicted_angle\n",
    "        # limit steering to max angel, say 40 degrees\n",
    "        if predicted_angle<-MAX_STEER_DEGREES:\n",
    "            steer_input = -MAX_STEER_DEGREES\n",
    "        elif predicted_angle>MAX_STEER_DEGREES:\n",
    "            steer_input = MAX_STEER_DEGREES\n",
    "        gen_dir_angle = get_distant_angle(vehicle,curr_wp,route,30)\n",
    "        initial_yaw = vehicle.get_transform().rotation.yaw\n",
    "        sem_im = camera_data['sem_image']\n",
    "        image = camera_data['rgb_image']\n",
    "        img_counter += 1\n",
    "        time_grab = time.time_ns()\n",
    "        cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(steer_input,0)), sem_im)\n",
    "        cv2.imshow('RGB Camera',image)\n",
    "        # only ouside intersections we spin the\n",
    "        if route[curr_wp][0].is_intersection==False and route[curr_wp][0].is_junction==False:\n",
    "            #grab images while spinning the car around\n",
    "            for i in range(3):\n",
    "                # Carla Tick\n",
    "                trans = vehicle.get_transform()\n",
    "                angle_adj = random.randrange(-MAX_SPIN, MAX_SPIN, 1)\n",
    "                trans.rotation.yaw = initial_yaw +angle_adj \n",
    "                vehicle.set_transform(trans)\n",
    "                world.tick()\n",
    "                time.sleep(2)  #these delays seem to be necessary for the car to take the position before a shot is taken\n",
    "                steer_input = predicted_angle - angle_adj # we put the opposite to correct back to straight\n",
    "                if steer_input<-MAX_STEER_DEGREES:\n",
    "                    steer_input = -MAX_STEER_DEGREES\n",
    "                elif steer_input>MAX_STEER_DEGREES:\n",
    "                    steer_input = MAX_STEER_DEGREES\n",
    "                sem_im = camera_data['sem_image']\n",
    "                img_counter += 1\n",
    "                time_grab = time.time_ns()\n",
    "                cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(steer_input,0)), sem_im)\n",
    "                image = camera_data['rgb_image']\n",
    "                image = cv2.putText(image, 'Steer: '+str(steer_input), (30,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('RGB Camera',image)\n",
    "                if cv2.waitKey(0) == ord('q'):\n",
    "                    quit = True\n",
    "                    break\n",
    "      \n",
    "    if quit:\n",
    "        break\n",
    "exit_clean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# manual tweaks\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "#client.load_world('Town03')\n",
    "\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "world.apply_settings(settings)\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "#clean up any existing cars\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "\n",
    "#look for a blueprint of Tesla m3 car\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "\n",
    "start_point = random.choice(spawn_points)\n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "time.sleep(2)\n",
    "# setting semantic camera\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "camera_bp.set_attribute('image_size_y', '480')\n",
    "camera_bp.set_attribute('fov', '90')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "image_w = 640\n",
    "image_h = 480\n",
    "\n",
    "camera_data = {'sem_image': np.zeros((image_h,image_w,4)),\n",
    "                'rgb_image': np.zeros((image_h,image_w,4))}\n",
    "\n",
    "    # this actually opens a live stream from the cameras\n",
    "camera_sem.listen(lambda image: sem_callback(image,camera_data))\n",
    "# adding collision sensor\n",
    "\n",
    "prev_position = vehicle.get_transform()\n",
    "# getting a random route for the car\n",
    "route = select_random_route(start_point,spawn_points)\n",
    "curr_wp = 2\n",
    "\n",
    "# move the car to next waypoint\n",
    "curr_wp +=1\n",
    "vehicle.set_transform(route[curr_wp][0].transform)\n",
    "draw_route(4, route,seconds=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exit_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.0\n",
      "-1\n",
      "150.97317504882812\n"
     ]
    }
   ],
   "source": [
    "_, predicted_angle = get_proper_angle(vehicle,curr_wp+5,route)\n",
    "gen_dir_angle = get_distant_angle(vehicle,curr_wp,route,30)\n",
    "initial_yaw = vehicle.get_transform().rotation.yaw\n",
    "print(round(predicted_angle,0))\n",
    "print(gen_dir_angle)\n",
    "print(initial_yaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#test spinning\n",
    "trans = vehicle.get_transform()\n",
    "angle_adj = random.randrange(-MAX_STEER_DEGREES, MAX_STEER_DEGREES, 1)\n",
    "trans.rotation.yaw = initial_yaw +angle_adj \n",
    "vehicle.set_transform(trans)\n",
    "print(angle_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_wp = 39\n",
    "vehicle.set_transform(route[curr_wp][0].transform)\n",
    "draw_route(curr_wp, route,seconds=10.0)\n",
    "cur_point = route[curr_wp][0]\n",
    "cur_point.is_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_route(curr_wp+5, route,seconds=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start from basics - working version with just RGB cam\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90 # field of view = focal length\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup():\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "start_point = spawn_points[0]\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "time.sleep(2)\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "camera_bp.set_attribute('fov', str(FOV))\n",
    "camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "#this creates the camera in the sim\n",
    "camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "# this actually opens a live stream from the camera\n",
    "camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "\n",
    "cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('RGB Camera',camera_data['image'])\n",
    "\n",
    "while True:\n",
    "    # Display with imshow\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    \n",
    "    # Break loop if user presses q\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for actor in world.get_actors().filter('*sensor*'):\n",
    "    actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# working version in Sync = False mode\n",
    "# adding semantic segm camera to above\n",
    "# this saves semantic images into _tst folder\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90 # field of view = focal length\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup():\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "start_point = spawn_points[0]\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "time.sleep(2)\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "#RGB CAM\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "camera_bp.set_attribute('fov', str(FOV))\n",
    "camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "#this creates the camera in the sim\n",
    "camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "               'sem_image': np.zeros((image_h,image_w,3))}\n",
    "# this actually opens a live stream from the camera\n",
    "camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "#Semantgic cam\n",
    "sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "#this creates the camera in the sim\n",
    "sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "# this actually opens a live stream from the camera\n",
    "#sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "time.sleep(2) #- this prevents black images but misses out on initial images\n",
    "cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('RGB Camera',camera_data['image'])\n",
    "\n",
    "while True:\n",
    "    # Display with imshow\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    time_grab = time.time_ns()\n",
    "    cv2.imwrite('_tst/%06d.png' % (time_grab), camera_data['sem_image'])    \n",
    "    # Break loop if user presses q\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try above in Synchronous mode\n",
    "# this works\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90 # field of view = focal length\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup():\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "start_point = spawn_points[0]\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "time.sleep(2)\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "#RGB CAM\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "camera_bp.set_attribute('fov', str(FOV))\n",
    "camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "#this creates the camera in the sim\n",
    "camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "               'sem_image': np.zeros((image_h,image_w,3))}\n",
    "# this actually opens a live stream from the camera\n",
    "camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "#Semantgic cam\n",
    "sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "#this creates the camera in the sim\n",
    "sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "# this actually opens a live stream from the camera\n",
    "#sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('RGB Camera',camera_data['image'])\n",
    "\n",
    "while True:\n",
    "    world.tick()\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    # Display with imshow\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    time_grab = time.time_ns()\n",
    "    sem_image = camera_data['sem_image']\n",
    "    if np.sum(sem_image) > 0:   #check for black images\n",
    "        cv2.imwrite('_tst/%06d.png' % (time_grab), sem_image)    \n",
    "    # Break loop if user presses q\n",
    "cv2.destroyAllWindows()\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8456\\814578965.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_control\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVehicleControl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthrottle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#these delays seem to be necessary for teh car to take the position before a shot is taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[0minitial_yaw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaypoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# add navigation loops to above\n",
    "# This is final working version, but needs to be interrupted manually\n",
    "# when you think you got enough images\n",
    "\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90 # field of view = focal length\n",
    "\n",
    "YAW_ADJ_DEGREES = 25 #random spin angle max\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup():\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "# function to get angle between the car and target waypoint\n",
    "def get_angle(car,wp):\n",
    "    '''\n",
    "    this function returns degrees between the car's direction \n",
    "    and direction to a selected waypoint\n",
    "    '''\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    # vector to waypoint\n",
    "    if ((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5 == 0:\n",
    "        x=0\n",
    "        y=0\n",
    "    else:\n",
    "        x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        \n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "\n",
    "def get_distant_angle(car,wp_idx,rte, delta):\n",
    "    '''\n",
    "    This function modifies the function above to get angle to a waypoint\n",
    "    at a distance so we could use it for training image generation\n",
    "    \n",
    "    We will display the angle for now in the 'telemetry' view so\n",
    "    we could play with how far forward we need to pick the waypoint\n",
    "    '''\n",
    "    if wp_idx + delta < len(rte)-1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte)-1\n",
    "    # check for intersection within the \"look forward\"\n",
    "    # so we do not give turn results when just following the road\n",
    "    intersection_detected = False\n",
    "    for x in range(i-wp_idx):\n",
    "        if rte[wp_idx+x][0].is_junction:\n",
    "             intersection_detected = True\n",
    "    angle = get_angle(car,rte[i][0])\n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    elif angle <-10:\n",
    "        result = -1\n",
    "    elif angle>10:\n",
    "        result =1\n",
    "    else:\n",
    "        result = 0    \n",
    "    return result\n",
    "\n",
    "def draw_route(wp, route,seconds=3.0):\n",
    "    #draw the next few points route in sim window - Note it does not\n",
    "    # get into the camera of the car\n",
    "    if len(route)-wp <25: # route within 25 points from end is red\n",
    "        draw_colour = carla.Color(r=255, g=0, b=0)\n",
    "    else:\n",
    "        draw_colour = carla.Color(r=0, g=0, b=255)\n",
    "    for i in range(10):\n",
    "        if wp+i<len(route)-2:\n",
    "            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n",
    "                color=draw_colour, life_time=seconds,\n",
    "                persistent_lines=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    '''\n",
    "    retruns a random route for the car/veh\n",
    "    out of the list of possible locations locs\n",
    "    where distance is longer than 100 waypoints\n",
    "    '''    \n",
    "    point_a = position.location #we start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # now let' pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: # we start trying all spawn points \n",
    "                                #but we just exclude first at zero index\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    " \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "quit = False\n",
    "while not quit:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    " \n",
    "    #RGB CAM\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(FOV))\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "                'sem_image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "    #Semantgic cam\n",
    "    sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "    #this creates the camera in the sim\n",
    "    sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "    sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    #sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "    sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    #make a route\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    for idx, waypoint in enumerate(route): # move the car through the route\n",
    "        #world.tick()\n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "        time.sleep(2) #these delays seem to be necessary for teh car to take the position before a shot is taken\n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        \n",
    "        for i in range(5):\n",
    "            #world.tick()         \n",
    "            trans = waypoint[0].transform\n",
    "            angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "            trans.rotation.yaw = initial_yaw +angle_adj \n",
    "            vehicle.set_transform(trans)\n",
    "            vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "            time.sleep(1)  #these delays seem to be necessary for the car to take the position before a shot is taken\n",
    "            gen_dir_angle = get_distant_angle(vehicle,idx,route,30) # general angle taken before spinning the car\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                quit = True\n",
    "                break\n",
    "            # Display with imshow\n",
    "            cv2.imshow('RGB Camera',camera_data['image'])\n",
    "            # save semantic image watching out for end of route    \n",
    "            if idx +5 < len(route)-1:\n",
    "                predicted_angle = get_angle(vehicle,route[idx+5][0]) # we always get the angle to +5 waypoint ahead of us\n",
    "                \n",
    "                time_grab = time.time_ns()\n",
    "                sem_image = camera_data['sem_image']\n",
    "                if np.sum(sem_image) > 0:   #check for black images\n",
    "                    cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(predicted_angle,0)), sem_image)\n",
    "    cleanup()\n",
    "    if quit:\n",
    "        break\n",
    "    # Break loop if user presses q\n",
    "cv2.destroyAllWindows()\n",
    "cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'world' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2568\\3245474554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_actors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*vehicle*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_actors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*sensor*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'world' is not defined"
     ]
    }
   ],
   "source": [
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for actor in world.get_actors().filter('*sensor*'):\n",
    "    actor.destroy()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2568\\1076367620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_control\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVehicleControl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthrottle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#these delays seem to be necessary for the car to take the position before a shot is taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# adding Checks for lane changes \n",
    "# images from waypoints before lane changes should be IGNORED\n",
    "# as they have \"sudden\" unexplained\n",
    "\n",
    "# This is a working version, but needs to be interrupted manually\n",
    "# when you think you got enough images\n",
    "\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90 # field of view = focal length\n",
    "\n",
    "YAW_ADJ_DEGREES = 25 #random spin angle max\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup():\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "# function to get angle between the car and target waypoint\n",
    "def get_angle(car,wp):\n",
    "    '''\n",
    "    this function returns degrees between the car's direction \n",
    "    and direction to a selected waypoint\n",
    "    '''\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    # vector to waypoint\n",
    "    if ((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5 == 0:\n",
    "        x=0\n",
    "        y=0\n",
    "    else:\n",
    "        x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        \n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "\n",
    "def get_distant_angle(car,wp_idx,rte, delta):\n",
    "    '''\n",
    "    This function modifies the function above to get angle to a waypoint\n",
    "    at a distance so we could use it for training image generation\n",
    "    \n",
    "    We will display the angle for now in the 'telemetry' view so\n",
    "    we could play with how far forward we need to pick the waypoint\n",
    "    '''\n",
    "    if wp_idx + delta < len(rte)-1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte)-1\n",
    "    # check for intersection within the \"look forward\"\n",
    "    # so we do not give turn results when just following the road\n",
    "    intersection_detected = False\n",
    "    for x in range(i-wp_idx):\n",
    "        if rte[wp_idx+x][0].is_junction or rte[wp_idx+x][0].is_intersection:\n",
    "             intersection_detected = True\n",
    "    angle = get_angle(car,rte[i][0])\n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    elif angle <-10:\n",
    "        result = -1\n",
    "    elif angle>10:\n",
    "        result =1\n",
    "    else:\n",
    "        result = 0    \n",
    "    return result\n",
    "\n",
    "def draw_route(wp, route,seconds=5.0):\n",
    "    #draw the next few points route in sim window - Note it does not\n",
    "    # get into the camera of the car\n",
    "    if len(route)-wp <25: # route within 25 points from end is red\n",
    "        draw_colour = carla.Color(r=255, g=0, b=0)\n",
    "    else:\n",
    "        draw_colour = carla.Color(r=0, g=0, b=255)\n",
    "    for i in range(15):\n",
    "        if wp+i<len(route)-2:\n",
    "            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n",
    "                color=draw_colour, life_time=seconds,\n",
    "                persistent_lines=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    '''\n",
    "    retruns a random route for the car/veh\n",
    "    out of the list of possible locations locs\n",
    "    where distance is longer than 100 waypoints\n",
    "    '''    \n",
    "    point_a = position.location #we start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # now let' pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: # we start trying all spawn points \n",
    "                                #but we just exclude first at zero index\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    " \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "quit = False\n",
    "while not quit:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    " \n",
    "    #RGB CAM\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(FOV))\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "                'sem_image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "    #Semantgic cam\n",
    "    sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "    #this creates the camera in the sim\n",
    "    sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "    sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    #sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "    sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    #make a route\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    gen_dir_angle = 0 # in case we did not get a general GPS direction\n",
    "    for idx, waypoint in enumerate(route): # move the car through the route\n",
    "        \n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "        time.sleep(2) #these delays seem to be necessary for teh car to take the position before a shot is taken\n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        # GPS general direction is only taken outside intersections\n",
    "        # so that direction is retained throughout the same intersection until it is finished\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            gen_dir_angle = get_distant_angle(vehicle,idx,route,30) # general angle taken before spinning the car\n",
    "        # logic to detect a lane change and ignore/not take those images\n",
    "        draw_route(idx, route,seconds=5.0)\n",
    "        lane_change = False\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            if idx < len(route)-2:\n",
    "                if route[idx][0].lane_id != route[idx+1][0].lane_id:\n",
    "                    lane_change = True\n",
    "        if not lane_change:\n",
    "            for i in range(5):\n",
    "                trans = waypoint[0].transform\n",
    "                angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "                trans.rotation.yaw = initial_yaw +angle_adj \n",
    "                vehicle.set_transform(trans)\n",
    "                vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "                time.sleep(1)  #these delays seem to be necessary for the car to take the position before a shot is taken\n",
    "                \n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    quit = True\n",
    "                    break\n",
    "                # Display with imshow\n",
    "                cv2.imshow('RGB Camera',camera_data['image'])\n",
    "                # save semantic image watching out for end of route    \n",
    "                if idx +5 < len(route)-1:\n",
    "                    predicted_angle = get_angle(vehicle,route[idx+5][0]) # we always get the angle to +5 waypoint ahead of us\n",
    "                    \n",
    "                    time_grab = time.time_ns()\n",
    "                    sem_image = camera_data['sem_image']\n",
    "                    if np.sum(sem_image) > 0:   #check for black images\n",
    "                        cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(predicted_angle,0)), sem_image)\n",
    "    cleanup()\n",
    "    if quit:\n",
    "        break\n",
    "    # Break loop if user presses q\n",
    "cv2.destroyAllWindows()\n",
    "cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15188\\3931056063.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_control\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVehicleControl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthrottle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#these delays seem to be necessary for the car to take the position before a shot is taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;31m# Display with imshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cleaning direction function\n",
    "# right and left can be done only at upcoming intersections\n",
    "# or at lane changes\n",
    "\n",
    "# This is a working version, but needs to be interrupted manually\n",
    "# when you think you got enough images\n",
    "\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "\n",
    "SHOW_RGB = False\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90 # field of view = focal length\n",
    "\n",
    "YAW_ADJ_DEGREES = 15 #random spin angle max\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup():\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "# function to get angle between the car and target waypoint\n",
    "def get_angle(car,wp):\n",
    "    '''\n",
    "    this function returns degrees between the car's direction \n",
    "    and direction to a selected waypoint\n",
    "    '''\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    # vector to waypoint\n",
    "    if ((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5 == 0:\n",
    "        x=0\n",
    "        y=0\n",
    "    else:\n",
    "        x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        \n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "\n",
    "#latest get direction function\n",
    "def get_distant_angle(car,wp_idx,rte, delta):\n",
    "    '''\n",
    "    This function determines general direction\n",
    "    given what we are planning to do at an oncoming intersection\n",
    "    so if we are within delta points from an intersection\n",
    "    we check our route at the intersection to decide what we do at it\n",
    "    '''\n",
    "    if wp_idx + delta < len(rte)-1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte)-1\n",
    "    # check for intersection within the \"look forward\"\n",
    "    # so we do not give turn results when just following the road\n",
    "    intersection_detected = False\n",
    "    for x in range(i-wp_idx):\n",
    "        if rte[wp_idx+x][0].is_junction:\n",
    "             intersection_detected = True\n",
    "             intersection_ref = wp_idx+x\n",
    "             break\n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    else: #we check out the intersection\n",
    "        angles_planned = [] # this is a list of angles towards current exit from the intersection\n",
    "        all_angles = []\n",
    "        #this is how to get all waypoints defining an intersection\n",
    "        junction_wps = rte[intersection_ref][0].get_junction().get_waypoints(carla.LaneType.Driving)\n",
    "        for wp in junction_wps:\n",
    "            angle = int(get_angle(car,wp[1])) \n",
    "            #this 'if' below excludes close exits points to entry - exits for which you would need to take u-turns so they do not count\n",
    "            if wp[1].transform.location.distance(route[intersection_ref][0].transform.location) > 20: \n",
    "                # check all exits for proximity to our route so we can flag the exit we are planning to take\n",
    "                for i in range(intersection_ref,len(route)-1):\n",
    "                    if wp[1].transform.location.distance(route[i][0].transform.location) < 10:\n",
    "                        angles_planned.append(angle)\n",
    "                    else:\n",
    "                        all_angles.append(angle)\n",
    "        angles_planned = list(set(angles_planned))\n",
    "        all_angles = list(set(all_angles))\n",
    "        alternative_angles = [item for item in all_angles if item not in angles_planned] \n",
    "        if len(alternative_angles) == 0 or len(angles_planned) == 0:\n",
    "            result = 0\n",
    "        elif min(angles_planned)<-25 and (min(alternative_angles) > min(angles_planned)):\n",
    "            #we are planningleft turn\n",
    "            result = -1\n",
    "        elif max(angles_planned)>25 and (max(alternative_angles) < max(angles_planned)):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0  \n",
    "    return result\n",
    "\n",
    "def draw_route(wp, route,seconds=5.0):\n",
    "    #draw the next few points route in sim window - Note it does not\n",
    "    # get into the camera of the car\n",
    "    if len(route)-wp <25: # route within 25 points from end is red\n",
    "        draw_colour = carla.Color(r=255, g=0, b=0)\n",
    "    else:\n",
    "        draw_colour = carla.Color(r=0, g=0, b=255)\n",
    "    for i in range(50):\n",
    "        if wp+i<len(route)-2:\n",
    "            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n",
    "                color=draw_colour, life_time=seconds,\n",
    "                persistent_lines=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    '''\n",
    "    retruns a random route for the car/veh\n",
    "    out of the list of possible locations locs\n",
    "    where distance is longer than 100 waypoints\n",
    "    '''    \n",
    "    point_a = position.location #we start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # now let' pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: # we start trying all spawn points \n",
    "                                #but we just exclude first at zero index\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    " \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "settings.no_rendering_mode = True\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "quit = False\n",
    "while not quit:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    " \n",
    "    #RGB CAM\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(FOV))\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "                'sem_image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "    #Semantgic cam\n",
    "    sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "    #this creates the camera in the sim\n",
    "    sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "    sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    #sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "    sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "    if SHOW_RGB:\n",
    "        cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    #make a route\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    gen_dir_angle = 0 # in case we did not get a general GPS direction\n",
    "    for idx, waypoint in enumerate(route): # move the car through the route\n",
    "        \n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "        time.sleep(2) #these delays seem to be necessary for teh car to take the position before a shot is taken\n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        # GPS general direction is only taken outside intersections\n",
    "        # so that direction is retained throughout the same intersection until it is finished\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            gen_dir_angle = get_distant_angle(vehicle,idx,route,30) # general angle taken before spinning the car\n",
    "        # logic to detect a lane change and ignore/not take those images\n",
    "        draw_route(idx, route,seconds=5.0)\n",
    "        lane_change = False\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            if idx < len(route)-2:\n",
    "                if route[idx][0].lane_id != route[idx+1][0].lane_id:\n",
    "                    lane_change = True\n",
    "        if lane_change: # lane changes are treated as turns in general direction\n",
    "            if get_angle(vehicle,route[idx+1][0])<0:\n",
    "                gen_dir_angle = -1\n",
    "            else:\n",
    "                gen_dir_angle = 1\n",
    "\n",
    "        for i in range(5):\n",
    "            trans = waypoint[0].transform\n",
    "            angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "            trans.rotation.yaw = initial_yaw +angle_adj \n",
    "            vehicle.set_transform(trans)\n",
    "            vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "            time.sleep(1)  #these delays seem to be necessary for the car to take the position before a shot is taken\n",
    "            \n",
    "            # Display with imshow\n",
    "            if SHOW_RGB:\n",
    "                cv2.imshow('RGB Camera',camera_data['image'])\n",
    "            # save semantic image watching out for end of route    \n",
    "            if idx +5 < len(route)-1:\n",
    "                predicted_angle = get_angle(vehicle,route[idx+5][0]) # we always get the angle to +5 waypoint ahead of us\n",
    "                \n",
    "                time_grab = time.time_ns()\n",
    "                sem_image = camera_data['sem_image']\n",
    "                if np.sum(sem_image) > 0:   #check for black images\n",
    "                    cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(predicted_angle,0)), sem_image)\n",
    "    cleanup()\n",
    "    if quit:\n",
    "        break\n",
    "    # Break loop if user presses q\n",
    "cv2.destroyAllWindows()\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CarlaSim",
   "language": "python",
   "name": "carla-sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
